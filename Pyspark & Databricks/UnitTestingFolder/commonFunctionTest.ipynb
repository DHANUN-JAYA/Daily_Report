{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8385c781-ce07-42f6-a25b-d788c8dc5522",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Users/sadhu.dhanunjay@diggibyte.com/unitTestingFolder/mainCommonFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "361d7f3a-8846-4768-8e4a-c7f0bed97296",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Users/sadhu.dhanunjay@diggibyte.com/unitTestingFolder/ProcessorTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8082c8a2-abb4-4ea7-98fa-86d0c1b4d67c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    " Verify if primary key/ composite key is having  any duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c034a525-ef3f-47fd-82f4-dd803bcfa8dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_duplicate_primary_key_ (__main__.test_duplicate_primary_key) ... ok\n\n----------------------------------------------------------------------\nRan 1 test in 2.180s\n\nOK\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[104]: <unittest.runner.TextTestResult run=1 errors=0 failures=0>"
     ]
    }
   ],
   "source": [
    "path=\"dbfs:/FileStore/tbro\"\n",
    "format_name=\"csv\"\n",
    "options={\"Header\":True,\"InferSchema\":True}\n",
    "df=create_df(path,format_name,**options)\n",
    "primary_key_columns = ['name']\n",
    "suite = unittest.TestSuite()\n",
    "suite.addTest(est_duplicate_primary_key('test_duplicate_primary_key_', df, primary_key_columns))  # Passing values of c and d dynamically\n",
    "\n",
    "unittest.TextTestRunner(verbosity=2).run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a49e9979-5aa8-4030-bb4a-5a8985dbcf9d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Verify ifprimary key/ composite keyis not nullable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f60c562-c588-4bae-9d70-42dff3d0f932",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_non_null_primary_key (__main__.test_duplicate_primary_key) ... ok\n\n----------------------------------------------------------------------\nRan 1 test in 1.698s\n\nOK\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[105]: <unittest.runner.TextTestResult run=1 errors=0 failures=0>"
     ]
    }
   ],
   "source": [
    "path=\"dbfs:/FileStore/tbro\"\n",
    "format_name=\"csv\"\n",
    "options={\"Header\":True,\"InferSchema\":True}\n",
    "df=create_df(path,format_name,**options)\n",
    "primary_key_columns = 'name'\n",
    "suite = unittest.TestSuite()\n",
    "suite.addTest(test_duplicate_primary_key('test_non_null_primary_key', df, primary_key_columns))  # Passing values of c and d dynamically\n",
    "\n",
    "unittest.TextTestRunner(verbosity=2).run(suite)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0bb948b4-a363-46fd-adb0-e3dfed9e03a1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Verify if any records are going to quarantine path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2762a533-fe7a-488a-8fda-ecc3eef5472c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_records_going_to_quarantine_path (__main__.test_duplicate_primary_key) ... ok\n\n----------------------------------------------------------------------\nRan 1 test in 0.734s\n\nOK\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[84]: <unittest.runner.TextTestResult run=1 errors=0 failures=0>"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "            Row(id=1, name='John', age=30, quarantine_flag=False),\n",
    "            Row(id=2, name='Alice', age=None, quarantine_flag=True),\n",
    "            Row(id=3, name='Bob', age=25, quarantine_flag=False),\n",
    "            Row(id=4, name=None, age=40, quarantine_flag=False),\n",
    "            Row(id=5, name='Jane', age=35, quarantine_flag=True)\n",
    "        ]\n",
    "\n",
    "        # Define schema for DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"quarantine_flag\", BooleanType(), True)\n",
    "])\n",
    "df = spark.createDataFrame(data, schema)\n",
    "suite = unittest.TestSuite()\n",
    "suite.addTest(test_duplicate_primary_key('test_records_going_to_quarantine_path', df))  \n",
    "\n",
    "unittest.TextTestRunner(verbosity=2).run(suite)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "377410bf-c641-4402-ab8a-d1216a21d4bb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Verify Audit Column  silver & Gold layer is mentioned as \"load_date\" in format \"yyyy-MM-dd HH:mm:SS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbe8832c-d84f-4d25-b13a-806e82172791",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_audit_column (__main__.test_duplicate_primary_key) ... ok\n\n----------------------------------------------------------------------\nRan 1 test in 0.002s\n\nOK\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[94]: <unittest.runner.TextTestResult run=1 errors=0 failures=0>"
     ]
    }
   ],
   "source": [
    "silver_data = [\n",
    "        (\"John\", 30, datetime.now()),\n",
    "        (\"Alice\", 25, datetime.now()),\n",
    "        (\"Bob\", 40, datetime.now())\n",
    "        ]\n",
    "\n",
    "# Define schema for Silver layer\n",
    "silver_schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", StringType(), True),\n",
    "    StructField(\"load_date\", TimestampType(), True)\n",
    "    ])\n",
    "\n",
    "        # Create DataFrame for Silver layer\n",
    "silver_df = spark.createDataFrame(silver_data, schema=silver_schema)\n",
    "\n",
    "# Sample data for Gold layer\n",
    "gold_data = [\n",
    "    (\"John\", 30, datetime.now()),\n",
    "    (\"Alice\", 25, datetime.now()),\n",
    "    (\"Bob\", 40, datetime.now())\n",
    "]\n",
    "\n",
    "# Define schema for Gold layer\n",
    "gold_schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", StringType(), True),\n",
    "    StructField(\"load_date\", TimestampType(), True)\n",
    "])\n",
    "# Create DataFrame for Gold layer\n",
    "gold_df = spark.createDataFrame(gold_data, schema=gold_schema)\n",
    "suite = unittest.TestSuite()\n",
    "suite.addTest(test_duplicate_primary_key('test_audit_column',silver_df,gold_df ))  \n",
    "\n",
    "unittest.TextTestRunner(verbosity=2).run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2fc3e355-3288-44b8-a972-8a00e48c09c7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Verify the file format type as raw and location in Bronze Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f860b88a-d7c8-41b1-a9b8-cc12a0b3b20f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_file_format (__main__.test_duplicate_primary_key) ... ok\n\n----------------------------------------------------------------------\nRan 1 test in 0.001s\n\nOK\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[106]: <unittest.runner.TextTestResult run=1 errors=0 failures=0>"
     ]
    }
   ],
   "source": [
    "raw_location=\"dbfs:/FileStore/Nested_json_file__1_-1.json\"\n",
    "bronze_location=\"dbfs:/FileStore/Nested_json_file__1_-1.json\"\n",
    "suite = unittest.TestSuite()\n",
    "suite.addTest(test_duplicate_primary_key('test_file_format',silver_df,gold_df ))  \n",
    "\n",
    "unittest.TextTestRunner(verbosity=2).run(suite)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4158b34-dc00-4091-acf1-2d50b6ef747b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Verify that the columns coming from the source file having data is ingested in Databricks - specially when you define a custom schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c273d3cd-dbe5-4741-8d9c-0be2d13e8fd9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_data_ingestion (__main__.test_duplicate_primary_key) ... ok\n\n----------------------------------------------------------------------\nRan 1 test in 0.003s\n\nOK\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[116]: <unittest.runner.TextTestResult run=1 errors=0 failures=0>"
     ]
    }
   ],
   "source": [
    "# Define custom schema\n",
    "custom_schema = StructType([\n",
    "    StructField(\"column1\", StringType(), nullable=False),\n",
    "    StructField(\"column2\", IntegerType(), nullable=True),\n",
    "    StructField(\"column3\", DateType(), nullable=True)\n",
    "    # Add more fields as needed\n",
    "])\n",
    "# Read data with defined schema\n",
    "source_file_path = \"dbfs:/FileStore/Nested_json_file__1_-1.json\"\n",
    "df = spark.read.csv(source_file_path, schema=custom_schema)\n",
    "suite = unittest.TestSuite()\n",
    "suite.addTest(test_duplicate_primary_key('test_data_ingestion',silver_df,gold_df ))  \n",
    "\n",
    "unittest.TextTestRunner(verbosity=2).run(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f09c6ef9-efee-427d-a81c-bada2ca0bd5d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d398ec8-06a2-498a-bb70-90518787cf59",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_add (__main__.test_) ... ok\ntest_sub (__main__.test_) ... ok\n\n----------------------------------------------------------------------\nRan 2 tests in 0.004s\n\nOK\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[25]: <unittest.runner.TextTestResult run=2 errors=0 failures=0>"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import datetime \n",
    "class test_(unittest.TestCase):\n",
    "    def test_add(self):\n",
    "        a=3\n",
    "        b=5\n",
    "        x=add(a,b)\n",
    "        y=a+b\n",
    "        self.assertEqual(x, y)\n",
    "    def test_sub(self):\n",
    "        c=12\n",
    "        d=3\n",
    "        x=sub(c,d)\n",
    "        y=c-d\n",
    "        self.assertEqual(x, y)\n",
    "\n",
    "s = unittest.TestLoader().loadTestsFromTestCase(test_)\n",
    "unittest.TextTestRunner(verbosity=2).run(s)\n",
    "# c=test_()\n",
    "# d=c.test_add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bc571b5-f821-494b-8bc2-283f373487a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_add (__main__.test_) ... ok\n\n----------------------------------------------------------------------\nRan 1 test in 0.002s\n\nOK\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[27]: <unittest.runner.TextTestResult run=1 errors=0 failures=0>"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import datetime \n",
    "\n",
    "class test_(unittest.TestCase):\n",
    "    def test_add(self):\n",
    "        a = 3\n",
    "        b = 5\n",
    "        x = add(a, b)\n",
    "        y = a + b\n",
    "        self.assertEqual(x, y)\n",
    "\n",
    "    def test_sub(self):\n",
    "        c = 12\n",
    "        d = 3\n",
    "        x = sub(c, d)\n",
    "        y = c - d\n",
    "        self.assertEqual(x, y)\n",
    "\n",
    "suite = unittest.TestSuite()\n",
    "suite.addTest(test_('test_add'))  # Adding only the test_sub method to the suite\n",
    "\n",
    "unittest.TextTestRunner(verbosity=2).run(suite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85101009-7af7-437a-b8e6-d92da09bbe35",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2187394809084719>:22\u001B[0m\n",
       "\u001B[1;32m     19\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39massertEqual(x, y)\n",
       "\u001B[1;32m     21\u001B[0m suite \u001B[38;5;241m=\u001B[39m unittest\u001B[38;5;241m.\u001B[39mTestSuite()\n",
       "\u001B[0;32m---> 22\u001B[0m suite\u001B[38;5;241m.\u001B[39maddTest(test_(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest_sub\u001B[39m\u001B[38;5;124m'\u001B[39m, c\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m12\u001B[39m, d\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m))  \u001B[38;5;66;03m# Passing values of c and d dynamically\u001B[39;00m\n",
       "\u001B[1;32m     24\u001B[0m unittest\u001B[38;5;241m.\u001B[39mTextTestRunner(verbosity\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39mrun(suite)\n",
       "\n",
       "\u001B[0;31mTypeError\u001B[0m: __init__() got an unexpected keyword argument 'c'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-2187394809084719>:22\u001B[0m\n\u001B[1;32m     19\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39massertEqual(x, y)\n\u001B[1;32m     21\u001B[0m suite \u001B[38;5;241m=\u001B[39m unittest\u001B[38;5;241m.\u001B[39mTestSuite()\n\u001B[0;32m---> 22\u001B[0m suite\u001B[38;5;241m.\u001B[39maddTest(test_(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest_sub\u001B[39m\u001B[38;5;124m'\u001B[39m, c\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m12\u001B[39m, d\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m))  \u001B[38;5;66;03m# Passing values of c and d dynamically\u001B[39;00m\n\u001B[1;32m     24\u001B[0m unittest\u001B[38;5;241m.\u001B[39mTextTestRunner(verbosity\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39mrun(suite)\n\n\u001B[0;31mTypeError\u001B[0m: __init__() got an unexpected keyword argument 'c'",
       "errorSummary": "<span class='ansi-red-fg'>TypeError</span>: __init__() got an unexpected keyword argument 'c'",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import unittest\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import datetime \n",
    "\n",
    "class test_(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.a = 12\n",
    "        self.b = 3\n",
    "\n",
    "    def test_add(self):\n",
    "        x = self.a + self.b\n",
    "        y = add(self.a, self.b)\n",
    "        self.assertEqual(x, y)\n",
    "\n",
    "    def test_sub(self):\n",
    "        x = sub(self.a, self.b)\n",
    "        y = self.a - self.b\n",
    "        self.assertEqual(x, y)\n",
    "\n",
    "suite = unittest.TestSuite()\n",
    "suite.addTest(test_('test_sub', c=12, d=3))  # Passing values of c and d dynamically\n",
    "\n",
    "unittest.TextTestRunner(verbosity=2).run(suite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d878f59-a8f7-4e9c-b7d4-caabb427bb1e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_sub (__main__.CustomTestCase) ... ok\n\n----------------------------------------------------------------------\nRan 1 test in 0.002s\n\nOK\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[30]: <unittest.runner.TextTestResult run=1 errors=0 failures=0>"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import datetime \n",
    "\n",
    "class CustomTestCase(unittest.TestCase):\n",
    "    def __init__(self, methodName='runTest', c=None, d=None):\n",
    "        super(CustomTestCase, self).__init__(methodName)\n",
    "        self.c = c\n",
    "        self.d = d\n",
    "\n",
    "    def setUp(self):\n",
    "        # Your setUp code here\n",
    "        pass\n",
    "\n",
    "    def test_add(self):\n",
    "        # Your test_add code here\n",
    "        pass\n",
    "\n",
    "    def test_sub(self):\n",
    "        x = sub(self.c, self.d)\n",
    "        y = self.c - self.d\n",
    "        self.assertEqual(x, y)\n",
    "\n",
    "suite = unittest.TestSuite()\n",
    "suite.addTest(CustomTestCase('test_sub', c=12, d=3))  # Passing values of c and d dynamically\n",
    "\n",
    "unittest.TextTestRunner(verbosity=2).run(suite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b62dc270-f30b-496f-99e1-c207dbd62d58",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def find_duplicate_column(df, column_name):\n",
    "    df2 = df.groupBy(column_name)\n",
    "    df_count = df2.filter(\"count > 1\").count()\n",
    "    assert df_count 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d2fb4f7-cedd-4b55-9415-85500ec50a36",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "find_duplicate_column()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "commonFunctionTest",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
